{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kohya's Script + Lora Train\n",
    "\n",
    "**Another Choice**: https://github.com/ddPn08/kohya-sd-scripts-webui\n",
    "\n",
    "More info: https://github.com/wibus-wee/stable_diffusion_chilloutmix_ipynb\n",
    "\n",
    "> Created by [@wibus-wee](https://github.com/wibus-wee)\n",
    ">\n",
    "> Reference: [camenduru/stable-diffusion-webui-colab](https://github.com/camenduru/stable-diffusion-webui-colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 选择模型 { display-mode: \"form\" }\n",
    "\n",
    "#@markdown 选择模型\n",
    "checkpoint = 'chilloutmix.safetensors' #@param [\"chilloutmix.safetensors\", \"sunshinemix.safetensors\", \"grapefruitHentaiModel.safetensors\"]\n",
    "\n",
    "downloadLink = {\n",
    "    'chilloutmix.safetensors': 'https://civitai.com/api/download/models/11745',\n",
    "    'sunshinemix.safetensors': 'https://civitai.com/api/download/models/11752',\n",
    "    'grapefruitHentaiModel.safetensors': 'https://civitai.com/api/download/models/9000'\n",
    "}[checkpoint]\n",
    "\n",
    "print(\"已选择模型: \" + checkpoint + \" <===> \" + downloadLink)\n",
    "\n",
    "%store checkpoint\n",
    "%store downloadLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. 安装训练依赖\n",
    "\n",
    "%store -r rootDir \n",
    "%store -r checkpoint\n",
    "%store -r downloadLink\n",
    "\n",
    "!apt-get -y install -qq aria2\n",
    "ariaInstalled = False\n",
    "\n",
    "try:\n",
    "    subprocess.run(['aria2c', '--version'], stdout=subprocess.PIPE)\n",
    "    ariaInstalled = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "!git clone --recurse-submodules https://github.com/Akegarasu/lora-scripts {rootDir}/lora-scripts\n",
    "\n",
    "%cd {rootDir}/lora-scripts\n",
    "if ariaInstalled:\n",
    "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {downloadLink} -d {rootDir}/lora-scripts/sd-models -o {checkpoint}\n",
    "else:\n",
    "    !wget -c {downloadLink} -P {rootDir}/stable-diffusion-webui/models/Stable-diffusion -O {rootDir}/lora-scripts/sd-models/{checkpoint}\n",
    "!chmod +x install.bash\n",
    "!bash install.bash # xformer install is very slow\n",
    "# !pip install torch==1.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "# !pip install -q https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.16/xformers-0.0.16+814314d.d20230118-cp38-cp38-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2. 训练选项设置\n",
    "%store -r rootDir \n",
    "%store -r checkpoint \n",
    "\n",
    "!source venv/bin/activate\n",
    "\n",
    "#@markdown 底膜路径 - 已跟随 Checkpoint 设置\n",
    "pretrained_model = rootDir + \"/lora-scripts/sd-models/\" + checkpoint\n",
    "#@markdown 训练数据集路径\n",
    "#@markdown PaperSpace 如果是在 Files 上传文件请加入 /notebooks/ 前缀，在 Google Colab 请加入 /content/ 前缀\n",
    "train_data_dir = \"<your_prefix>/<img_parent_dir>\" #@param {type:\"string\"}\n",
    "#@markdown 导出模型路径\n",
    "#@markdown PaperSpace 如果是在 Files 上传文件请加入 /notebooks/ 前缀，在 Google Colab 请加入 /content/ 前缀\n",
    "export_model_dir = \"<your_prefix>/<model_export_dir>\" #@param {type:\"string\"}\n",
    "#@markdown output model name | 模型保存名称\n",
    "output_name = \"lora_v1.0\" #@param {type:\"string\"}\n",
    "#@markdown model save ext | 模型保存格式 ckpt, pt, safetensors\n",
    "save_model_as = \"safetensors\" #@param [\"ckpt\", \"pt\", \"safetensors\"] {type:\"string\"}\n",
    "#@markdown 图片分辨率，宽,高。支持非正方形，但必须是 64 倍数。\n",
    "resolution = \"512,512\" #@param [\"256,256\", \"512,512\", \"1024,1024\", \"2048,2048\"]\n",
    "#@markdown batch size | 批大小\n",
    "batch_size = 1 #@param {type:\"number\"}\n",
    "#@markdown max train epoches | 最大训练 epoch\n",
    "max_train_epoches = 10 #@param {type:\"number\"}\n",
    "#@markdown save every n epochs | 每 N 个 epoch 保存一次\n",
    "save_every_n_epochs = 2 #@param {type:\"number\"}\n",
    "#@markdown network dim | 常用 4~128，不是越大越好\n",
    "network_dim = 32 #@param {type:\"number\"}\n",
    "#@markdown network alpha | 常用与 network_dim 相同的值或者采用较小的值，如 network_dim的一半 防止下溢。默认值为 1，使用较小的 alpha 需要提升学习率。\n",
    "network_alpha = 32 #@param {type:\"number\"}\n",
    "#@markdown clip skip | 玄学 一般用 2\n",
    "clip_skip = 2 #@param {type:\"number\"}\n",
    "#@markdown train U-Net only | 仅训练 U-Net，开启这个会牺牲效果大幅减少显存使用。6G显存可以开启\n",
    "train_unet_only = False #@param {type:\"boolean\"}\n",
    "#@markdown train Text Encoder only | 仅训练 文本编码器\n",
    "train_text_encoder_only = False #@param {type:\"boolean\"}\n",
    "#@markdown 学习率\n",
    "lr = \"1e-4\" #@param {type:\"string\"}\n",
    "#@markdown unet_lr | U-Net 学习率\n",
    "unet_lr = \"1e-4\" #@param {type:\"string\"}\n",
    "#@markdown text_encoder_lr | 文本编码器学习率\n",
    "text_encoder_lr = \"1e-5\" #@param {type:\"string\"}\n",
    "#@markdown lr_scheduler | \"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"\n",
    "lr_scheduler = \"cosine_with_restarts\" #@param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"] {type:\"string\"}\n",
    "#@markdown lr_warmup_steps | 仅在 lr_scheduler 为 constant_with_warmup 时需要填写这个值\n",
    "lr_warmup_steps = 0 #@param {type:\"number\"}\n",
    "#@markdown 若需要从已有的 LoRA 模型上继续训练，请填写 LoRA 模型路径。\n",
    "network_weights = \"\" #@param {type:\"string\"}\n",
    "#@markdown arb min resolution | arb 最小分辨率\n",
    "min_bucket_reso = 256 #@param {type:\"number\"}\n",
    "#@markdown arb max resolution | arb 最大分辨率\n",
    "max_bucket_reso = 1024 #@param {type:\"number\"}\n",
    "#@markdown persistent dataloader workers | 容易爆内存，保留加载训练集的worker，减少每个 epoch 之间的停顿\n",
    "persistent_data_loader_workers = 0 #@param {type:\"number\"}\n",
    "#@markdown use 8bit adam optimizer | 使用 8bit adam 优化器节省显存，默认启用。部分 10 系老显卡无法使用，修改为 0 禁用。\n",
    "use_8bit_adam = True #@param {type:\"boolean\"}\n",
    "#@markdown use lion optimizer | 使用 Lion 优化器\n",
    "use_lion = False #@param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. 开始训练\n",
    "!accelerate launch --num_cpu_threads_per_process=8 \"./sd-scripts/train_network.py\" \\\n",
    "  --enable_bucket \\\n",
    "  --pretrained_model_name_or_path=$pretrained_model \\\n",
    "  --train_data_dir=$train_data_dir \\\n",
    "  --output_dir=$export_model_dir \\\n",
    "  --logging_dir=\"/tmp/logs\" \\\n",
    "  --resolution=$resolution \\\n",
    "  --network_module=networks.lora \\\n",
    "  --max_train_epochs=$max_train_epoches \\\n",
    "  --learning_rate=$lr \\\n",
    "  --unet_lr=$unet_lr \\\n",
    "  --text_encoder_lr=$text_encoder_lr \\\n",
    "  --lr_scheduler=$lr_scheduler \\\n",
    "  --lr_warmup_steps=$lr_warmup_steps \\\n",
    "  --network_dim=$network_dim \\\n",
    "  --network_alpha=$network_alpha \\\n",
    "  --output_name=$output_name \\\n",
    "  --train_batch_size=$batch_size \\\n",
    "  --save_every_n_epochs=$save_every_n_epochs \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --save_precision=\"fp16\" \\\n",
    "  --seed=\"1337\" \\\n",
    "  --cache_latents \\\n",
    "  --clip_skip=$clip_skip \\\n",
    "  --prior_loss_weight=1 \\\n",
    "  --max_token_length=225 \\\n",
    "  --caption_extension=\".txt\" \\\n",
    "  --save_model_as=$save_model_as \\\n",
    "  --min_bucket_reso=$min_bucket_reso \\\n",
    "  --max_bucket_reso=$max_bucket_reso \\\n",
    "  --use_8bit_adam=$use_8bit_adam \\\n",
    "  --shuffle_caption --xformer"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
