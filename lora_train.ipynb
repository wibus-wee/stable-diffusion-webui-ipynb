{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kohya's Script + Lora Train\n",
    "\n",
    "**Another Choice**: https://github.com/ddPn08/kohya-sd-scripts-webui\n",
    "\n",
    "More info: https://github.com/wibus-wee/stable_diffusion_chilloutmix_ipynb\n",
    "\n",
    "> Created by [@wibus-wee](https://github.com/wibus-wee)\n",
    ">\n",
    "> Reference: [camenduru/stable-diffusion-webui-colab](https://github.com/camenduru/stable-diffusion-webui-colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import requests\n",
    "\n",
    "#@title Choose checkpoint { display-mode: \"form\" }\n",
    "endpoint = 'https://civitai.com/api/v1/models'\n",
    "#@markdown Checkpoint（ If you want to use your own model, please select \"others\" and fill in the \"Other checkpoint\" below.）\n",
    "checkpointName = 'Chilloutmix' #@param [\"Chilloutmix\", \"Sunshinemix\", \"grapefruit_hentai\", \"others\"]\n",
    "#@markdown Other checkpoint （Checkpoint ID in civitai , only support one model)\n",
    "checkpointID = '' #@param {type:\"string\"}\n",
    "#@markdown Other checkpoint （Checkpoint download URL, only support one model)\n",
    "checkpointURL = '' #@param {type:\"string\"}\n",
    "\n",
    "\n",
    "defaultCheckpoint = {\n",
    "    'Chilloutmix': '6424',\n",
    "    'Sunshinemix': '9291',\n",
    "    'grapefruit_hentai': '2583'\n",
    "}\n",
    "\n",
    "downloadIds = []\n",
    "\n",
    "if checkpointID != '':\n",
    "    downloadIds = checkpointID.split(',')\n",
    "if checkpointName != 'others':\n",
    "        downloadIds.append(defaultCheckpoint[checkpointName])\n",
    "\n",
    "globalDropdowns = []\n",
    "globalVerions = []\n",
    "globalNames = []\n",
    "globalTexts = []\n",
    "checkpoints = []\n",
    "downloadLinks = []\n",
    "\n",
    "def text_on_submit(change):\n",
    "    checkpoints[checkpoints.index(change['old'])] = change['new']\n",
    "\n",
    "if checkpointURL != '':\n",
    "    _downloadLinks = checkpointURL.split(',')\n",
    "    for _downloadLink in _downloadLinks:\n",
    "        checkpoints.append(_downloadLink.split('/')[-1])\n",
    "        downloadLinks.append(_downloadLink)\n",
    "        text = widgets.Text(value=_downloadLink.split('/')[-1], description=_downloadLink.split('/')[-1], disabled=False)\n",
    "        text.observe(text_on_submit, names='value')\n",
    "        form = widgets.VBox([text])\n",
    "        display(form)\n",
    "\n",
    "def showVerionOptions(downloadId):\n",
    "    res = requests.get(endpoint + '/' + downloadId).json()\n",
    "    globalNames.append(res['name'])\n",
    "    versions = res['modelVersions']\n",
    "    globalVerions.append(versions)\n",
    "    options = []\n",
    "    for version in versions:\n",
    "        options.append(version['files'][0]['name'])\n",
    "    dropdown = widgets.Dropdown(options=options, description=res['name'])\n",
    "    globalDropdowns.append(dropdown)\n",
    "    form = widgets.VBox([dropdown])\n",
    "    display(form)\n",
    "\n",
    "for downloadId in downloadIds:\n",
    "    showVerionOptions(downloadId)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    downloadLink = None\n",
    "    for dropdown in globalDropdowns:\n",
    "        checkpoint = dropdown.value\n",
    "        versions = globalVerions[globalDropdowns.index(dropdown)]\n",
    "        for version in versions:\n",
    "            if version['files'][0]['name'] == checkpoint:\n",
    "                downloadLink = version['files'][0]['downloadUrl']\n",
    "                break\n",
    "        if downloadLink is None:\n",
    "            print('Error: downloadLink not assigned')\n",
    "            return\n",
    "        checkpoints.append(checkpoint)\n",
    "        downloadLinks.append(downloadLink)\n",
    "\n",
    "    print(\"Checkpoint \" + str(checkpoints) + \" <===> \" + str(downloadLinks))\n",
    "    %store checkpoint\n",
    "    %store downloadLink\n",
    "\n",
    "\n",
    "button = widgets.Button(description='Use it!')\n",
    "button.on_click(on_button_clicked)\n",
    "display(button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 0. Check GPU & Check Environment { display-mode: \"form\" }\n",
    "\n",
    "#@markdown This step will check if your GPU is supported by xformers, and check if you are using Paperspace (only M4000 GPU is checked, so paid GPUs may have logical errors here, you may need to check the \"isPaperspace\" checkbox manually).\n",
    "\n",
    "import os, subprocess\n",
    "paperspace_m4000 = False\n",
    "#@markdown ⬇️ True: Paperspace | False: Colab\n",
    "isPaperspace = False #@param {type:\"boolean\"}\n",
    "try:\n",
    "    subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], stdout=subprocess.PIPE)\n",
    "    if 'M4000' in subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], stdout=subprocess.PIPE).stdout.decode('utf-8'):\n",
    "        print(\"WARNING: You are using Quadro M4000 GPU, which will not be able to use xformers.\")\n",
    "        paperspace_m4000 = True\n",
    "        isPaperspace = True\n",
    "    else:\n",
    "        print(\"You are using a suitable GPU - \" + subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], stdout=subprocess.PIPE).stdout.decode('utf-8') + \".\"\n",
    "except:\n",
    "    print(\"The GPU is not available. Please check your runtime type.\")\n",
    "    exit()\n",
    "\n",
    "rootDir = isPaperspace and '/tmp' or '/content'\n",
    "\n",
    "%store rootDir\n",
    "%store paperspace_m4000 \n",
    "%store isPaperspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Install Dependencies\n",
    "\n",
    "#@markdown ⬇️ True: Install xformers | False: Skip (Only for Paperspace M4000 GPU, if you choose this option, xformers will be installed from source code)\n",
    "xformersInstall = True #@param {type:\"boolean\"}\n",
    "\n",
    "%store -r rootDir \n",
    "%store -r checkpoint\n",
    "%store -r downloadLink\n",
    "%store -r paperspace_m4000\n",
    "\n",
    "!apt-get -y install -qq aria2\n",
    "ariaInstalled = False\n",
    "\n",
    "try:\n",
    "    subprocess.run(['aria2c', '--version'], stdout=subprocess.PIPE)\n",
    "    ariaInstalled = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "!git clone --recurse-submodules https://github.com/Akegarasu/lora-scripts {rootDir}/lora-scripts\n",
    "\n",
    "%cd {rootDir}/lora-scripts\n",
    "if ariaInstalled:\n",
    "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {downloadLink} -d {rootDir}/lora-scripts/sd-models -o {checkpoint}\n",
    "else:\n",
    "    !wget -c {downloadLink} -P {rootDir}/stable-diffusion-webui/models/Stable-diffusion -O {rootDir}/lora-scripts/sd-models/{checkpoint}\n",
    "\n",
    "\n",
    "!echo \"Installing deps...\"\n",
    "%cd ./sd-scripts\n",
    "!pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "!pip install --upgrade -r requirements.txt\n",
    "if paperspace_m4000:\n",
    "  if xformersInstall:\n",
    "    !pip install ninja\n",
    "    !pip install -v -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers\n",
    "    !pip install --pre triton\n",
    "else:\n",
    "  !pip install -q https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.16/xformers-0.0.16+814314d.d20230118-cp38-cp38-linux_x86_64.whl\n",
    "  !pip install --pre triton\n",
    "!pip install --upgrade lion-pytorch\n",
    "\n",
    "echo \"Install completed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2. Setup Training Options\n",
    "%store -r rootDir \n",
    "%store -r checkpoint \n",
    "\n",
    "!source venv/bin/activate\n",
    "\n",
    "#@markdown 底膜路径 - 已跟随 Checkpoint 设置 | Pretrained model path - Followed by Checkpoint\n",
    "pretrained_model = rootDir + \"/lora-scripts/sd-models/\" + checkpoint\n",
    "#@markdown 训练数据集路径 | Training dataset path\n",
    "#@markdown PaperSpace 如果是在 Files 上传文件请加入 /notebooks/ 前缀，在 Google Colab 请加入 /content/ 前缀\n",
    "#@markdown If you upload the file to Files in PaperSpace, please add the /notebooks/ prefix. If you upload the file to Google Colab, please add the /content/ prefix.\n",
    "train_data_dir = \"<your_prefix>/<img_parent_dir>\" #@param {type:\"string\"}\n",
    "#@markdown 导出模型路径 | Export model path\n",
    "#@markdown PaperSpace 如果是在 Files 上传文件请加入 /notebooks/ 前缀，在 Google Colab 请加入 /content/ 前缀\n",
    "#@markdown If you upload the file to Files in PaperSpace, please add the /notebooks/ prefix. If you upload the file to Google Colab, please add the /content/ prefix.\n",
    "export_model_dir = \"<your_prefix>/<model_export_dir>\" #@param {type:\"string\"}\n",
    "#@markdown 模型保存名称 | output model name\n",
    "output_name = \"lora_v1.0\" #@param {type:\"string\"}\n",
    "#@markdown  模型保存格式 | model save ext (ckpt, pt, safetensors)\n",
    "save_model_as = \"safetensors\" #@param [\"ckpt\", \"pt\", \"safetensors\"] {type:\"string\"}\n",
    "#@markdown 图片分辨率 | image resolution\n",
    "#@markdown (宽,高). 支持非正方形，但必须是 64 倍数。 | (width, height). Non-square images are supported, but must be a multiple of 64.\n",
    "resolution = \"512,512\" #@param [\"256,256\", \"512,512\", \"1024,1024\", \"2048,2048\"]\n",
    "#@markdown batch size | 批大小\n",
    "batch_size = 1 #@param {type:\"number\"}\n",
    "#@markdown max train epoches | 最大训练 epoch\n",
    "max_train_epoches = 10 #@param {type:\"number\"}\n",
    "#@markdown save every n epochs | 每 N 个 epoch 保存一次\n",
    "save_every_n_epochs = 2 #@param {type:\"number\"}\n",
    "#@markdown network dim | 常用 4~128，不是越大越好 | A value between 4 and 128. Not necessarily the larger the better.\n",
    "network_dim = 32 #@param {type:\"number\"}\n",
    "#@markdown network alpha\n",
    "#@markdown 常用与 network_dim 相同的值或者采用较小的值，如 network_dim的一半 防止下溢。默认值为 1，使用较小的 alpha 需要提升学习率。\n",
    "#@markdown A value between 1 and network_dim. Not necessarily the larger the better. Default value is 1. Use a smaller alpha value to prevent underflow. You may need to increase the learning rate.\n",
    "network_alpha = 32 #@param {type:\"number\"}\n",
    "#@markdown clip skip | 玄学 一般用 2 | Usually 2.\n",
    "clip_skip = 2 #@param {type:\"number\"}\n",
    "#@markdown train U-Net only | 仅训练 U-Net，开启这个会牺牲效果大幅减少显存使用。6G显存可以开启 | This will sacrifice the quality of the model, but it will reduce the memory usage. 6G GPU memory can be enabled.\n",
    "train_unet_only = False #@param {type:\"boolean\"}\n",
    "#@markdown train Text Encoder only | 仅训练 文本编码器\n",
    "train_text_encoder_only = False #@param {type:\"boolean\"}\n",
    "#@markdown 学习率 | Learning rate\n",
    "lr = \"1e-4\" #@param {type:\"string\"}\n",
    "#@markdown unet_lr | U-Net 学习率 | Learning rate of the U-Net\n",
    "unet_lr = \"1e-4\" #@param {type:\"string\"}\n",
    "#@markdown text_encoder_lr | 文本编码器学习率 | Learning rate of the text encoder\n",
    "text_encoder_lr = \"1e-5\" #@param {type:\"string\"}\n",
    "#@markdown lr_scheduler | \"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"\n",
    "lr_scheduler = \"cosine_with_restarts\" #@param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"] {type:\"string\"}\n",
    "#@markdown lr_warmup_steps | 仅在 lr_scheduler 为 constant_with_warmup 时需要填写这个值 | Only needed when lr_scheduler is constant_with_warmup\n",
    "lr_warmup_steps = 0 #@param {type:\"number\"}\n",
    "#@markdown 若需要从已有的 LoRA 模型上继续训练，请填写 LoRA 模型路径。 | If you want to continue training from an existing LoRA model, please fill in the LoRA model path.\n",
    "network_weights = \"\" #@param {type:\"string\"}\n",
    "#@markdown arb min resolution | arb 最小分辨率\n",
    "min_bucket_reso = 256 #@param {type:\"number\"}\n",
    "#@markdown arb max resolution | arb 最大分辨率\n",
    "max_bucket_reso = 1024 #@param {type:\"number\"}\n",
    "#@markdown persistent dataloader workers | 容易爆内存，保留加载训练集的worker，减少每个 epoch 之间的停顿 | Persistent dataloader workers, reduce the pause between each epoch\n",
    "persistent_data_loader_workers = 0 #@param {type:\"number\"}\n",
    "#@markdown use 8bit adam optimizer | 使用 8bit adam 优化器节省显存，默认启用。部分 10 系老显卡无法使用，修改为 0 禁用。 | Use 8bit adam optimizer to save memory. Default is enabled. Some 10 series old GPUs cannot use it. Set to 0 to disable.\n",
    "use_8bit_adam = True #@param {type:\"boolean\"}\n",
    "#@markdown use lion optimizer | 使用 Lion 优化器 | Use Lion optimizer\n",
    "use_lion = False #@param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. Start training\n",
    "!accelerate launch --num_cpu_threads_per_process=8 \"./sd-scripts/train_network.py\" \\\n",
    "  --enable_bucket \\\n",
    "  --pretrained_model_name_or_path=$pretrained_model \\\n",
    "  --train_data_dir=$train_data_dir \\\n",
    "  --output_dir=$export_model_dir \\\n",
    "  --logging_dir=\"/tmp/logs\" \\\n",
    "  --resolution=$resolution \\\n",
    "  --network_module=networks.lora \\\n",
    "  --max_train_epochs=$max_train_epoches \\\n",
    "  --learning_rate=$lr \\\n",
    "  --unet_lr=$unet_lr \\\n",
    "  --text_encoder_lr=$text_encoder_lr \\\n",
    "  --lr_scheduler=$lr_scheduler \\\n",
    "  --lr_warmup_steps=$lr_warmup_steps \\\n",
    "  --network_dim=$network_dim \\\n",
    "  --network_alpha=$network_alpha \\\n",
    "  --output_name=$output_name \\\n",
    "  --train_batch_size=$batch_size \\\n",
    "  --save_every_n_epochs=$save_every_n_epochs \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --save_precision=\"fp16\" \\\n",
    "  --seed=\"1337\" \\\n",
    "  --cache_latents \\\n",
    "  --clip_skip=$clip_skip \\\n",
    "  --prior_loss_weight=1 \\\n",
    "  --max_token_length=225 \\\n",
    "  --caption_extension=\".txt\" \\\n",
    "  --save_model_as=$save_model_as \\\n",
    "  --min_bucket_reso=$min_bucket_reso \\\n",
    "  --max_bucket_reso=$max_bucket_reso \\\n",
    "  --use_8bit_adam=$use_8bit_adam \\\n",
    "  --shuffle_caption --xformer"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
